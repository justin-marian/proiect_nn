{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from voc import get_dataloader\n",
    "from main_utils import set_seed\n",
    "from model_factory import get_model\n",
    "from ema import RobustEMA\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31451bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (224, 224)\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "BATCH_SIZE = 4\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "METRIC_SUPERVISED = [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"]\n",
    "METRICS_UNSUPERVISED = [\"loss_classifier\", \"loss_objectness\"]\n",
    "LAMBDA_UNSUPERVISED = 5.0\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def scale_to_01(image, **kwargs):\n",
    "    return image.astype('float32') / 255.0\n",
    "\n",
    "weak_augmentations = A.Compose([\n",
    "    A.Resize(SIZE[0], SIZE[1]),         \n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Lambda(image=scale_to_01), \n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "strong_augmentations = A.Compose(\n",
    "        [\n",
    "            A.Resize(SIZE[0], SIZE[1]),\n",
    "            A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), sigma_limit=(0.1, 2.0), p=0.5),\n",
    "            A.CoarseDropout(num_holes_range=(3, 3), hole_height_range=(0.05, 0.1),\n",
    "                             hole_width_range=(0.05, 0.1), p=0.5),\n",
    "            A.Lambda(image=scale_to_01), \n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='pascal_voc')\n",
    "    )\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(SIZE[0], SIZE[1]),\n",
    "    A.Lambda(image=scale_to_01), \n",
    "    ToTensorV2(), \n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "\n",
    "dt_train_labeled = get_dataloader(\"trainval\", \"2007\", BATCH_SIZE, transform=weak_augmentations)\n",
    "dt_train_unlabeled_weakaug = get_dataloader(\"trainval\", \"2012\", BATCH_SIZE, transform=weak_augmentations) \n",
    "dt_train_unlabeled_strongaug = get_dataloader(\"trainval\", \"2012\", BATCH_SIZE, transform=strong_augmentations)\n",
    "dt_test = get_dataloader(\"test\", \"2007\", BATCH_SIZE, transform=test_transforms, shuffle=False)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6da2c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1180880994.py, line 40)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mout_path = os.path.join(save_dir, f{filename})\u001b[39m\n                                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def plot_losses(history, save_dir=None, filename=\"loss_plot.png\"):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    epochs = range(1, len(history[\"total\"]) + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for comp in METRIC_SUPERVISED:\n",
    "        plt.plot(epochs, history[f\"{comp}_supervised\"], label=f\"Train {comp}_supervised\", linewidth=2)\n",
    "    for comp in METRIC_SUPERVISED:\n",
    "        plt.plot(epochs, history[f\"{comp}_unsupervised\"], label=f\"Train {comp}_unsupervised\", linewidth=2)\n",
    "        \n",
    "    plt.plot(epochs, history[\"total\"], label=\"Train total\", linewidth=2)\n",
    "\n",
    "    plt.title(\"Training Loss Components Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save to disk\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        out_path = os.path.join(save_dir, f\"{filename}_{epochs}\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"[INFO] Plot saved to: {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ecaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, optimizer=None, device='cuda'):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = get_model(device=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model weights loaded from {checkpoint_path}\")\n",
    "\n",
    "    if optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"Optimizer state loaded from {checkpoint_path}\")\n",
    "\n",
    "    epoch = checkpoint.get('epoch', 0)\n",
    "    print(f\"Resuming from epoch {epoch}\")\n",
    "    return model, optimizer, epoch\n",
    "\n",
    "def train_burn_in(model, optimizer, dt_train_labeled, device):\n",
    "    model.train()\n",
    "    train_batches = 0\n",
    "    history = {key : 0 for key in METRIC_SUPERVISED}\n",
    "\n",
    "    for images, targets in tqdm(dt_train_labeled, desc=\"Training\"):\n",
    "        # if train_batches == 5: break\n",
    "        for target in targets:\n",
    "            target[\"boxes\"] = target[\"boxes\"].to(device)\n",
    "            target[\"labels\"] = target[\"labels\"].to(device)\n",
    "        images = images.to(device)\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for k, v in loss_dict.items():\n",
    "            history[k] += v.item()\n",
    "\n",
    "        history[\"total\"] += loss.item()\n",
    "        train_batches += 1\n",
    "    for key in history:\n",
    "        history[key] = history[key] / train_batches\n",
    "    return history\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "\n",
    "def pipeline_burn_in(epochs, dt_train_labeled, device, checkpoint_every):\n",
    "\n",
    "    model = get_model(device=device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    history = {key : [] for key in METRIC_SUPERVISED}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n==================== Epoch {epoch+1}/{epochs} ====================\\n\")\n",
    "        train_history = train_burn_in(model, optimizer, dt_train_labeled, device)\n",
    "        lr_scheduler.step(train_history[\"total\"])\n",
    "        for key, val in train_history.items():\n",
    "            history[key].append(val)\n",
    "        plot_losses(history)\n",
    "        if (epoch + 1) % checkpoint_every == 0 or (epoch + 1) == epochs:\n",
    "            checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            save_checkpoint(model, optimizer, epoch + 1, checkpoint_path)\n",
    "\n",
    "# pipeline_burn_in(50, dt_train_labeled, device, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a294f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dt_train_unlabeled_weakaug))\n",
    "from torchvision.ops import batched_nms\n",
    "NMS_IOU = 0.5\n",
    "def generate_pseudo_labels(model : torch.nn.Module, images : torch.Tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images, None)\n",
    "        for output in outputs:\n",
    "            boxes  = output[\"boxes\"]\n",
    "            labels = output[\"labels\"]\n",
    "            scores = output[\"scores\"]\n",
    "\n",
    "            keep_nms = batched_nms(\n",
    "                boxes, scores, labels,\n",
    "                iou_threshold=NMS_IOU\n",
    "            )\n",
    "            boxes  = boxes[keep_nms]\n",
    "            labels = labels[keep_nms]\n",
    "            scores = scores[keep_nms]\n",
    "\n",
    "            boxes_to_keep = scores > CONFIDENCE_THRESHOLD        \n",
    "            boxes  = boxes[boxes_to_keep]\n",
    "            labels = labels[boxes_to_keep]\n",
    "            scores = scores[boxes_to_keep]\n",
    "\n",
    "            output[\"boxes\"]  = boxes\n",
    "            output[\"labels\"] = labels\n",
    "            output[\"scores\"] = scores\n",
    "        return outputs       \n",
    "    \n",
    "# model, optimizer, epoch = load_checkpoint(checkpoint_path=checkpoint_path, optimizer=None, device=device)\n",
    "# generate_pseudo_labels(model, images, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from checkpoints/checkpoint_epoch_42.pth\n",
      "Resuming from epoch 42\n",
      "\n",
      "==================== Epoch 1/10 ====================\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 5.63 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 4.84 GiB memory in use. Of the allocated memory 4.28 GiB is allocated by PyTorch, and 446.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m         plot_losses(history)\n\u001b[32m     68\u001b[39m checkpoint_path=\u001b[33m\"\u001b[39m\u001b[33mcheckpoints/checkpoint_epoch_42.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mrun_semi_supervised_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_train_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_train_unlabeled_weakaug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_train_unlabeled_strongaug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mrun_semi_supervised_pipeline\u001b[39m\u001b[34m(checkpoint_path, epochs, dt_labeled, dt_weak, dt_strong, dt_test)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m==================== Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ====================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     train_history = \u001b[43mtrain_semi_supervised_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_weak\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_strong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     lr_scheduler.step(train_history[\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m train_history.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_semi_supervised_one_epoch\u001b[39m\u001b[34m(teacher, student, optimizer, dt_labeled, dt_weak, dt_strong)\u001b[39m\n\u001b[32m     31\u001b[39m optimizer.zero_grad()\n\u001b[32m     32\u001b[39m loss = \u001b[38;5;28msum\u001b[39m(loss_dict_supervised.values()) + LAMBDA_UNSUPERVISED * (loss_dict_unsupervised[\u001b[33m\"\u001b[39m\u001b[33mloss_classifier\u001b[39m\u001b[33m\"\u001b[39m] + loss_dict_unsupervised[\u001b[33m\"\u001b[39m\u001b[33mloss_objectness\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m optimizer.step()\n\u001b[32m     36\u001b[39m teacher.update(student)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nn/project/venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nn/project/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nn/project/venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 5.63 GiB of which 130.06 MiB is free. Including non-PyTorch memory, this process has 4.84 GiB memory in use. Of the allocated memory 4.28 GiB is allocated by PyTorch, and 446.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def train_semi_supervised_one_epoch(teacher : RobustEMA, student, optimizer, dt_labeled, dt_weak, dt_strong):\n",
    "    student.train()\n",
    "    train_batches = 0\n",
    "    history = {}\n",
    "    for key in METRIC_SUPERVISED:\n",
    "        history[f\"{key}_supervised\"] = 0\n",
    "    for key in METRICS_UNSUPERVISED:\n",
    "        history[f\"{key}_unsupervised\"] = 0\n",
    "    history[\"total\"] = 0\n",
    "\n",
    "    for (img_labeled, targets_labeled), (img_weak, _), (img_strong, _) in zip(dt_labeled, dt_weak, dt_strong):\n",
    "        if train_batches == 5: break\n",
    "        # SHOULD REPLACE THE TRANSFORMATION OF HORIZONTAL FLIP WITH SOMETHING PHOTOMETRIC\n",
    "        weak_targets = generate_pseudo_labels(teacher.ema, img_weak, device)\n",
    "        \n",
    "        for target in weak_targets:\n",
    "            target[\"boxes\"] = target[\"boxes\"].to(device)\n",
    "            target[\"labels\"] = target[\"labels\"].to(device)\n",
    "        img_strong = img_strong.to(device)\n",
    "        loss_dict_unsupervised = student(img_strong, weak_targets)\n",
    "\n",
    "        for target in targets_labeled:\n",
    "            target[\"boxes\"] = target[\"boxes\"].to(device)\n",
    "            target[\"labels\"] = target[\"labels\"].to(device)\n",
    "        img_labeled = img_labeled.to(device)\n",
    "        loss_dict_supervised = student(img_labeled, targets_labeled)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = sum(loss_dict_supervised.values()) + LAMBDA_UNSUPERVISED * (loss_dict_unsupervised[\"loss_classifier\"] + loss_dict_unsupervised[\"loss_objectness\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        teacher.update(student)\n",
    "        for k in METRICS_UNSUPERVISED:\n",
    "            history[f\"{k}_unsupervised\"] += loss_dict_unsupervised[k]\n",
    "        for k in METRIC_SUPERVISED:\n",
    "            history[f\"{k}_supervised\"] += loss_dict_supervised[k] \n",
    "\n",
    "        history[\"total\"] += loss.item()\n",
    "        train_batches += 1\n",
    "    for key in history:\n",
    "        history[key] = history[key] / train_batches\n",
    "    return history\n",
    "\n",
    "\n",
    "def run_semi_supervised_pipeline(checkpoint_path, epochs, dt_labeled, dt_weak, dt_strong, dt_test):\n",
    "    student, _, _ = load_checkpoint(checkpoint_path=checkpoint_path, optimizer=None, device=device)\n",
    "    teacher = RobustEMA(student)\n",
    "    optimizer = torch.optim.SGD(student.parameters(), lr=1e-2, momentum=0.9)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    history = {}\n",
    "    for key in METRIC_SUPERVISED:\n",
    "        history[f\"{key}_supervised\"] = []\n",
    "    for key in METRICS_UNSUPERVISED:\n",
    "        history[f\"{key}_unsupervised\"] = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n==================== Epoch {epoch+1}/{epochs} ====================\\n\")\n",
    "        train_history = train_semi_supervised_one_epoch(teacher, student, optimizer, dt_labeled, dt_weak, dt_strong)\n",
    "        lr_scheduler.step(train_history[\"total\"])\n",
    "        for key, val in train_history.items():\n",
    "            history[key].append(val)\n",
    "        plot_losses(history)\n",
    "\n",
    "checkpoint_path=\"checkpoints/checkpoint_epoch_42.pth\"\n",
    "run_semi_supervised_pipeline(checkpoint_path, 10, dt_train_labeled, dt_train_unlabeled_weakaug, dt_train_unlabeled_strongaug, dt_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
