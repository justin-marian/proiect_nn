{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from voc import get_dataloader\n",
    "from main_utils import set_seed\n",
    "from model_factory import get_model\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31451bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZE = (256, 256)\n",
    "import os\n",
    "SIZE = (160, 160)\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "BATCH_SIZE = 4\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def scale_to_01(image, **kwargs):\n",
    "    return image.astype('float32') / 255.0\n",
    "\n",
    "train_labeled_transforms = A.Compose([\n",
    "    A.Resize(SIZE[0], SIZE[1]),         \n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Lambda(image=scale_to_01), \n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "train_unlabeled_transforms = A.Compose(\n",
    "        [\n",
    "            A.Resize(SIZE[0], SIZE[1]),\n",
    "            A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), sigma_limit=(0.1, 2.0), p=0.5),\n",
    "            A.CoarseDropout(num_holes_range=(3, 3), hole_height_range=(0.05, 0.1),\n",
    "                             hole_width_range=(0.05, 0.1), p=0.5),\n",
    "            A.Lambda(image=scale_to_01), \n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='pascal_voc')\n",
    "    )\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(SIZE[0], SIZE[1]),\n",
    "    A.Lambda(image=scale_to_01), \n",
    "    ToTensorV2(), \n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "\n",
    "\n",
    "dt_train_labeled = get_dataloader(\"trainval\", \"2007\", BATCH_SIZE, transform=train_labeled_transforms)\n",
    "dt_train_unlabeled = get_dataloader(\"trainval\", \"2012\", BATCH_SIZE, transform=train_unlabeled_transforms)\n",
    "dt_test = get_dataloader(\"test\", \"2007\", BATCH_SIZE, transform=test_transforms, shuffle=False)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6da2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "METRIC_KEYS = [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\", \"total\"]\n",
    "\n",
    "def plot_losses(history):\n",
    "    epochs = range(1, len(history[\"total\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    for comp in METRIC_KEYS:\n",
    "        plt.plot(epochs, history[comp], label=f\"Train {comp}\", linewidth=2)\n",
    "    plt.title(f\"Train results over epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331ecaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def load_checkpoint(checkpoint_path, optimizer=None, device='cuda'):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = get_model(device=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model weights loaded from {checkpoint_path}\")\n",
    "\n",
    "    if optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"Optimizer state loaded from {checkpoint_path}\")\n",
    "\n",
    "    epoch = checkpoint.get('epoch', 0)\n",
    "    print(f\"Resuming from epoch {epoch}\")\n",
    "    return model, optimizer, epoch\n",
    "\n",
    "def train(model, optimizer, dt_train_labeled, device):\n",
    "    model.train()\n",
    "    train_batches = 0\n",
    "    history = {key : 0 for key in METRIC_KEYS}\n",
    "\n",
    "    for images, targets in tqdm(dt_train_labeled, desc=\"Training\"):\n",
    "        # if train_batches == 5: break\n",
    "        for target in targets:\n",
    "            target[\"boxes\"] = target[\"boxes\"].to(device)\n",
    "            target[\"labels\"] = target[\"labels\"].to(device)\n",
    "        images = images.to(device)\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for k, v in loss_dict.items():\n",
    "            history[k] += v.item()\n",
    "\n",
    "        history[\"total\"] += loss.item()\n",
    "        train_batches += 1\n",
    "    for key in history:\n",
    "        history[key] = history[key] / train_batches\n",
    "    return history\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "\n",
    "def pipeline(epochs, dt_train_labeled, device, checkpoint_every):\n",
    "\n",
    "    model = get_model(device=device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    history = {key : [] for key in METRIC_KEYS}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n==================== Epoch {epoch+1}/{epochs} ====================\\n\")\n",
    "        train_history = train(model, optimizer, dt_train_labeled, device)\n",
    "        lr_scheduler.step(train_history[\"total\"])\n",
    "        for key, val in train_history.items():\n",
    "            history[key].append(val)\n",
    "        plot_losses(history)\n",
    "        if (epoch + 1) % checkpoint_every == 0 or (epoch + 1) == epochs:\n",
    "            checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            save_checkpoint(model, optimizer, epoch + 1, checkpoint_path)\n",
    "\n",
    "# pipeline(30, dt_train_labeled, device, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dt_train_unlabeled))\n",
    "def generate_pseudo_labels(model : torch.nn.Module, images : torch.Tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images, None)\n",
    "        for output in outputs:\n",
    "            boxes_to_keep = output[\"scores\"] > CONFIDENCE_THRESHOLD        \n",
    "            output[\"boxes\"]  = output[\"boxes\"][boxes_to_keep]\n",
    "            output[\"labels\"] = output[\"labels\"][boxes_to_keep]\n",
    "            output[\"scores\"] = output[\"scores\"][boxes_to_keep]\n",
    "        return outputs       \n",
    "    \n",
    "model, optimizer, epoch = load_checkpoint(checkpoint_path=CHECKPOINT_DIR, optimizer=None, device=device)\n",
    "generate_pseudo_labels(model, images, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
